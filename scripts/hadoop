#!/bin/bash
#
#TIPS: https://dzone.com/articles/top-10-hadoop-shell-commands
RETVAL=0
HADOOP_HOME="/opt/hadoop-2.9.0"
TIMER=30

#----------------------------------------------------------------------
check_first_run(){
#for testing, force delete
#/opt/hadoop-2.9.0/bin/hadoop fs -rm -R /user
#printf "\033[1;33mChecking if first run...\033[0m\n"
IS_HADOOP_RUNNING=`ps -ef | grep hadoop | grep -P  'namenode|datanode|tasktracker|jobtracker'`
if [ -n "$IS_HADOOP_RUNNING" ]; then

#check for one time for directory, if not create dir and load files
if $($HADOOP_HOME/bin/hadoop fs -test -d "/user/root"); then
        printf "\033[1;33m/user/root alread exists. do nothing..\033[0m\n"
else
		printf "\033[1;32m\nThis is the first run for Hadoop...\033[0m\n"
        printf "\033[1;33mCreating /user and sub-directories\033[0m\n"
        $HADOOP_HOME/bin/hdfs dfs -mkdir -p /user/root/data/
        $HADOOP_HOME/bin/hdfs dfs -mkdir -p /user/root/data/avro/20170731
        $HADOOP_HOME/bin/hdfs dfs -mkdir -p /user/root/data/avro/20170801
        $HADOOP_HOME/bin/hdfs dfs -mkdir -p /user/root/archive/splunkaccesscombine_archive
        $HADOOP_HOME/bin/hdfs dfs -chmod -R 777 /user
        $HADOOP_HOME/bin/hadoop fs -chown -R splunk:splunk hdfs://localhost:8020/user/
        printf "\033[1;33mLoading HDFS directories with sample data\033[0m\n"
        $HADOOP_HOME/bin/hdfs dfs -put /tmp/Hunkdata.json.gz /user/root/data/
        $HADOOP_HOME/bin/hdfs dfs -put /tmp/avro_07_31_2017.avro /user/root/data/avro/20170731
        $HADOOP_HOME/bin/hdfs dfs -put /tmp/avro_08_01_2017.avro /user/root/data/avro/20170801
#	rm -f /tmp/Hunkdata.json.gz
#	rm -f /tmp/avro_07_31_2017.avro
#	rm -f /tmp/avro_08_01_2017.avro
        fi
fi
}
#----------------------------------------------------------------------
#----------------------------------------------------------------------
check_HDFS_var(){
#Hadoop will start by fault unless we dont want to (using ENV var)
if [ "$HDFS" = "NO" ] || [ "$HDFS" = "no" ]; then
 printf "\033[1;31mENV VAR is set HDFS=NO during docker run, must unset first (export HDFS=YES)\033[0m\n"
  printf "\033[1;31mWill not start HDFS...!\033[0m\n"
  exit
fi
}
#----------------------------------------------------------------------
#------------------------------------------------------------------
hadoop_start() {
check_HDFS_var
IS_HADOOP_RUNNING=`ps -ef | grep hadoop | grep -P  'namenode|datanode|tasktracker|jobtracker'`
if [ -n "$IS_HADOOP_RUNNING" ]; then
	printf "\033[1;33mHadoop is Already running...\033[0m\n"
else
      	printf "\033[1;33mStarting HDFS...\033[0m\n"
      	$HADOOP_HOME/sbin/start-dfs.sh
  	printf "\033[1;33mSync with supervisord [supervisorctl start hadoop_yarn]: "
	supervisorctl start hadoop_yarn
	printf "\033[0m\n"
      	printf "\033[1;33mPausing $TIMER seconds to give hadoop time to start (this will prevent safe-mode error when trying to load data too fast)\033[0m\n"
	sleep $TIMER
	check_first_run
fi
RETVAL=$?
}
#------------------------------------------------------------------
#------------------------------------------------------------------
hadoop_stop() {
printf "\033[1;33mStopping HDFS...\033[0m\n"
$HADOOP_HOME/sbin/stop-dfs.sh
printf "\033[1;33mSync with supervisord [supervisorctl stop hadoop_yarn]: "
supervisorctl stop hadoop_yarn
printf "\033[0m\n"
RETVAL=$?
}
#------------------------------------------------------------------
#------------------------------------------------------------------
hadoop_restart() {
check_HDFS_var
printf "\033[1;33mRestarting hadoop...\033[0m\n"
hadoop_stop
hadoop_start
RETVAL=$?
}
#------------------------------------------------------------------
hadoop_status() {
  printf "\033[1;33mhadoop_status():Not implemented function***\033[0m\n"
  RETVAL=$?
}
#------------------------------------------------------------------


case "$1" in
	start)
    		hadoop_start
    	;;
  	stop)
    		hadoop_stop
    	;;
  	restart)
    		hadoop_restart
    	;;
  	status)
    		hadoop_status
    	;;
  	*)
    	echo "Usage: $0 {start|stop|restart|status}"
    	exit 1
    	;;
esac

trap "$HADOOP_HOME/sbin/stop-dfs.sh" SIGINT SIGTERM
#Keep running if started by supervisord, otherwise terminate
MY_PID=$$
SUPERVISOR_PIDS=$(supervisorctl pid all)
#printf "\033[1;33mmy pid: [$MY_PID]  suprverisord pids:[$SUPERVISOR_PIDS]\033[0m\n"
if [[ "$SUPERVISOR_PIDS" =~ "$MY_PID" ]]; then
	while true; do continue;done
fi
exit $RETVAL
